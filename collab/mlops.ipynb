!pip install -q -U bitsandbytes accelerate transformers pymupdf

import os
import fitz
import re
import json
import pandas as pd
from datetime import datetime
from google.colab import drive
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig

drive.mount('/content/drive')

FOLDER_PATH = '/content/drive/MyDrive/modul_praktikum_sains_data'

model_id = "Qwen/Qwen2.5-1.5B-Instruct"

bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.float16,
)

print(f"Sedang memuat AI {model_id}...")
try:
    tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)
    model = AutoModelForCausalLM.from_pretrained(
        model_id,
        quantization_config=bnb_config,
        device_map="auto",
        trust_remote_code=True
    )
except Exception as e:
    print("‚ùå Error memuat model. Pastikan Anda menggunakan Runtime T4 GPU!")
    raise e

ABBREVIATION_MAP = {
    "Data Mining": "DM",
    "Pemodelan Stokastik": "PS",
    "Pergudangan Data": "PD",
    "Komputasi Paralel": "KP",
    "Analisis Data Statistik": "ADS",
    "Teknologi Basis Data": "TBD",
    "Basis Data": "BD",
    "Algoritma Pemrograman": "AP",
    "Deep Learning": "DL",
    "Machine Learning": "ML"
}

DAFTAR_MATKUL_AI = list(ABBREVIATION_MAP.keys())

def get_pdf_content(file_path):
    try:
        doc = fitz.open(file_path)
        text = ""
        for i in range(min(2, len(doc))):
            text += doc[i].get_text()
        doc.close()
        return re.sub(r'\s+', ' ', text).strip()[:2500]
    except:
        return ""

def ask_ai(text_content):
    system_prompt = "Kamu adalah asisten akademik ahli Sains Data. Tugasmu mengekstrak metadata modul praktikum."

    user_prompt = f"""
    Analisis teks modul praktikum berikut:
    ---
    {text_content}
    ---

    Ekstrak informasi berikut dalam format JSON Valid:
    1. "mata_kuliah_full": Pilih SATU yang paling relevan dari daftar ini: {DAFTAR_MATKUL_AI}.
    2. "judul_topik": Judul spesifik modul ini. (HAPUS kata 'Modul', 'Praktikum', 'Bab', 'Percobaan', atau Angka urutan di awal. Ambil inti judul teknisnya saja).
    3. "deskripsi": Buat ringkasan DETIL (3-4 kalimat). Jelaskan TUJUAN praktikum, METODE/ALGORITMA yang digunakan, dan TOOLS/LIBRARY yang dipakai (jika ada). Gunakan Bahasa Indonesia formal.

    Jawab HANYA JSON.
    """

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ]

    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    model_inputs = tokenizer([text], return_tensors="pt").to("cuda")

    generated_ids = model.generate(
        model_inputs.input_ids,
        max_new_tokens=450,
        temperature=0.1,
        do_sample=True
    )

    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]

    return response.split(user_prompt)[-1] if user_prompt in response else response

def parse_json_response(response):
    try:
        match = re.search(r'\{.*\}', response, re.DOTALL)
        if match: return json.loads(match.group(0))
    except: pass
    return None

if not os.path.exists(FOLDER_PATH):
    print(f"‚ùå Path Salah: {FOLDER_PATH}")
else:
    files = [os.path.join(FOLDER_PATH, f) for f in os.listdir(FOLDER_PATH) if f.lower().endswith(".pdf")]
    results = []

    print(f"\nüöÄ Memproses {len(files)} file PDF dengan AI...\n")

    for f_path in files:
        filename = os.path.basename(f_path)

        raw_text = get_pdf_content(f_path)
        if not raw_text: continue

        ai_raw = ask_ai(raw_text)
        data = parse_json_response(ai_raw)

        if data:
            full_mk = data.get("mata_kuliah_full", "Lainnya")
            l1_abbr = ABBREVIATION_MAP.get(full_mk, "OTH")
            l2_topic = data.get("judul_topik", "Topik Umum")
            desc = data.get("deskripsi", "Tidak ada deskripsi.")
        else:
            print(f"‚ö†Ô∏è Gagal parsing JSON: {filename}")
            l1_abbr, l2_topic, desc = "ERR", "Manual Check", "Error AI Response"

        print(f"[‚úÖ OK] {filename}")
        print(f"   L1 (Code) : {l1_abbr}")
        print(f"   L2 (Topik): {l2_topic}")
        print("-" * 40)

        results.append({
            'file_name': filename,
            'layer_1_code': l1_abbr,
            'layer_2_topic': l2_topic,
            'description': desc,
            'file_path': f_path,
            'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'updated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        })

    df = pd.DataFrame(results)
    output_csv = '/content/drive/MyDrive/indexing_final_db.csv'
    df.to_csv(output_csv, index=False)
    print(f"\nüíæ Selesai! Data tersimpan di: {output_csv}")

# Project MLOps: Repository Modul Praktikum Sains Data ğŸš€

**Sistem Repository Cerdas Berbasis Generative AI & Web Application**

Project ini bertujuan untuk membangun sistem manajemen untuk modul praktikum Sains Data. Sistem ini mengintegrasikan **Workflow MLOps** (Machine Learning Operations) mulai dari pengambilan data (Ingestion), pemrosesan menggunakan LLM (Large Language Model), hingga deployment ke aplikasi web interaktif dengan mekanisme monitoring *Human-in-the-Loop*.

-----

## ğŸ“‹ Daftar Isi

1.  Latar Belakang & Tujuan
2.  Arsitektur Sistem (Workflow)
3.  Tech Stack
4.  Implementasi MLOps 
      - Tahap 1: Build (Data & Modeling)
      - Tahap 2: Deploy (Serving)
      - Tahap 3: Monitor (Governance)
5.  Instalasi & Penggunaan
6.  Struktur Project
7.  Tim Pengembang

-----

## ğŸ¯ Latar Belakang & Tujuan

**Masalah:** Modul praktikum seringkali tercecer, tidak terstruktur, dan sulit dicari kembali oleh mahasiswa.
**Solusi:** Membangun repositori terpusat yang mampu membaca isi file PDF secara otomatis dan mengklasifikasikannya menggunakan AI.

**Objective (Tujuan Project):**

1.  **Mengenal Workflow MLOps:** Menerapkan siklus *Build, Deploy, Monitor*.
2.  **Otomatisasi Metadata:** Menggunakan GenAI untuk mengekstrak Judul, Topik, dan Deskripsi dari file PDF mentah.
3.  **Sentralisasi Data:** Menyajikan data dalam Web App yang *user-friendly*.

-----

## ğŸ— Arsitektur Sistem

Sistem ini menggunakan pendekatan **Hybrid Environment**:

1.  **AI Processing Environment (Google Colab):** Digunakan untuk menjalankan model LLM yang berat (Qwen 1.5B) menggunakan GPU T4.
2.  **Production Environment (Localhost/XAMPP):** Digunakan untuk *User Interface* dan Database manajemen.

-----

## ğŸ› ï¸ Tech Stack

| Komponen | Tools yang Digunakan | Fungsi Utama |
| :--- | :--- | :--- |
| **Data Ingestion** | Python, PyMuPDF (`fitz`), Google Drive | Membaca teks mentah dari file PDF. |
| **Preprocessing** | Python `re` (Regex), `json` | Membersihkan teks & parsing output AI. |
| **Model LLM** | **Qwen/Qwen2.5-1.5B-Instruct** | *In-Context Learning* untuk ekstraksi informasi. |
| **Optimization** | `bitsandbytes` (4-bit Quantization) | Optimasi memori agar berjalan di GPU gratisan. |
| **Framework** | Hugging Face `transformers`, PyTorch | Pipeline eksekusi model AI. |
| **Backend** | PHP Native (PDO) | Logika server dan API sederhana. |
| **Database** | MySQL | Menyimpan metadata terstruktur. |
| **Frontend** | HTML5, CSS3 (Modern UI), JS | Antarmuka pengguna (Dashboard/Search). |

-----

## ğŸš€ Implementasi MLOps

Bagian ini menjelaskan bagaimana project ini memenuhi komponen-komponen MLOps.

### Tahap 1: Build (Data & Modeling)

**1. Data Ingestion & Preparation**

  * **Code:** `mlops.ipynb`
  * **Proses:** Script secara otomatis memindai folder Google Drive (`FOLDER_PATH`). Menggunakan library `PyMuPDF` untuk mengekstrak teks hanya dari **2 halaman pertama** PDF (strategi efisiensi untuk mendapatkan konteks judul/topik).

**2. Data Preprocessing**

  * **Code:** `mlops.ipynb` (Fungsi `get_pdf_content` & `parse_json_response`)
  * **Proses:**
      * Membersihkan *whitespace* dan karakter non-standar menggunakan Regex.
      * *Truncating* teks maksimal 2500 karakter agar muat dalam *Context Window* LLM.

**3. Modeling (Generative AI Approach)**

  * **Code:** `mlops.ipynb`
  * **Model:** Menggunakan `Qwen2.5-1.5B-Instruct`.
  * **Teknik:**
      * **Quantization:** Menggunakan `load_in_4bit=True` untuk efisiensi komputasi.
      * **Prompt Engineering:** Menggunakan *System Prompt* ("Kamu adalah asisten akademik...") untuk memaksa model mengeluarkan output dalam format **JSON Valid**.
  * **Hyperparameter Tuning:**
      * `temperature = 0.1` (Sangat rendah agar output konsisten/deterministik).
      * `max_new_tokens = 450` (Agar deskripsi tidak terpotong).

**4. Packaging & Registering**

  * **Packaging:** Output prediksi dikemas dari JSON menjadi file CSV (`indexing_final_db.csv`).
  * **Registering:** File CSV diimpor ke Database MySQL (`import_data.php`) agar resmi terdaftar dalam sistem produksi.

-----

### Tahap 2: Deploy (Serving)

Sistem menggunakan strategi **Batch Inference** dengan **Web Serving**.

**1. Production Release**

  * Aplikasi web dideploy menggunakan server lokal (XAMPP/Apache).
  * File `index.php` bertindak sebagai *Serving Layer* dimana pengguna bisa mencari modul.

**2. Online Inference**

  * Meskipun model AI berjalan *offline* (batch), hasil inferensinya disajikan secara *online* melalui fitur pencarian (`script.js` & `api.php`).
  * Fitur **Upload Modul** (`upload.php`) memungkinkan penambahan data baru secara real-time ke dalam sistem.

-----

### Tahap 3: Monitor (Governance)

Menerapkan konsep **Human-in-the-Loop (HITL)** untuk mengatasi kelemahan AI (Halusinasi).

**1. Monitoring & Evaluation**

  * **Automated Evaluation:** Script Python memvalidasi format JSON sebelum disimpan. Jika format salah, dicatat sebagai `[Error AI Response]`.
  * **Human Evaluation:** Admin memantau hasil ekstraksi melalui **Admin Dashboard** (`admin.php`).

**2. Governance (Tata Kelola)**

  * Jika AI salah mendeteksi topik atau mata kuliah, Admin dapat melakukan **Intervensi Manual** melalui fitur `update.php`.
  * Sistem mencatat kapan data dibuat dan diperbarui (`created_at`, `updated_at`) untuk *audit trail*.

-----

## ğŸ’» Instalasi & Penggunaan

### Prasyarat

1.  Akun Google (untuk Colab).
2.  XAMPP (PHP & MySQL) terinstall di komputer lokal.

### Langkah 1: Jalankan AI Pipeline (Cloud)

1.  Buka file `mlops.ipynb` di Google Colab.
2.  Upload file PDF modul praktikum ke folder Google Drive.
3.  Jalankan semua cell. Script akan menghasilkan file `indexing_final_db.csv`.
4.  Download file CSV tersebut.

### Langkah 2: Setup Web App (Local)

1.  Clone repository ini ke folder `htdocs` di XAMPP.
2.  Buat database MySQL baru bernama `project_mlops`.
3.  Import tabel user dan documents (bisa pakai query SQL standar).
4.  Jalankan `reset_admin.php` untuk membuat user admin default (User: `admin`, Pass: `123`).
5.  Letakkan file CSV hasil AI di folder `data/`.
6.  Buka browser: `http://localhost/folder_project/import_data.php` untuk memasukkan hasil AI ke Database.

### Langkah 3: Akses Aplikasi

  * **Dashboard Mahasiswa:** `http://localhost/folder_project/index.php`
  * **Login Admin:** `http://localhost/folder_project/login.php`

-----

## ğŸ“‚ Struktur Project

```
project_mlops/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.php          # Koneksi Database
â”œâ”€â”€ data/
â”‚   â””â”€â”€ indexing_final_db.csv # Output dari Model AI
â”œâ”€â”€ uploads/                # Penyimpanan File PDF Fisik
â”œâ”€â”€ js/
â”‚   â”œâ”€â”€ script.js           # Logika Dashboard & Search
â”‚   â”œâ”€â”€ script_upload.js    # Logika Upload (Drag & Drop)
â”‚   â””â”€â”€ script_update.js    # Logika Update Data
â”œâ”€â”€ css/
â”‚   â”œâ”€â”€ style.css           # UI Utama (Modern Gradient)
â”‚   â”œâ”€â”€ style_admin.css     # UI Halaman Admin
â”‚   â””â”€â”€ ...
â”œâ”€â”€ mlops.ipynb             # [CORE] Script Python AI/MLOps
â”œâ”€â”€ index.php               # Halaman Utama (Serving Layer)
â”œâ”€â”€ admin.php               # Dashboard Monitoring
â”œâ”€â”€ import_data.php         # Script Registering Model Output
â”œâ”€â”€ api.php                 # API Endpoint JSON
â””â”€â”€ README.md               # Dokumentasi Project
```

-----

## ğŸ‘¥ Tim Pengembang

Project ini disusun untuk memenuhi Tugas Besar Mata Kuliah **Machine Learning Operations (MLOps)**, Program Studi Sains Data ITERA 2025.

  * **Platform:** GitHub
  * **Model ID:** `Qwen/Qwen2.5-1.5B-Instruct`

-----
